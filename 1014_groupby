# -*- coding: utf-8 -*-
run profile1

# multi_index_ex2.csv 파일을 읽고 (1_A => 1월의 A지점)
df1 = pd.read_csv('multi_index_ex2.csv', encoding = 'cp949')

# 멀티 컬럼 설정
Series(df1.columns).replace('^ ', NA, regex = True).ffill()      # 아래와 같은 행위
c1 = Series(df1.columns).map(lambda x : NA if ' ' in x else x).ffill()

df1.columns = [c1, df1.iloc[0,:]]
df1 = df1.drop(0, axis =0)

df1.columns.names = ['지역','요일']

# 멀티 인덱스 설정
vmonth = df1.iloc[:,0].str[0].astype('int')
vjj = df1.iloc[:,0].str[2:]
df1.index = [vmonth, vjj]

df1.index.names = ['월','지점']


# 불필요 컬럼 제거
df1 = df1.iloc[:,1:]


# 특수문자를 NA로 변환
df1.replace([',','.','?','-'],NA).astype('float')        # 아래와 같은 행위
df1 = df1.replace('\W',NA, regex = True).astype('float')

df1.dtypes


# --
df1.sum(axis = 0, level = 0)            # axis는 방향, level은 그룹연산
df1.sum(axis = 1, level = 1)


# 1) 지역별 요일별 판매량의 총 합
df1.sum(axis = 0)

# 2) 지역별 요일별 지점별 판매량의 총 합
df1.xs('A', axis=0,level = 1).sum(axis = 0)
df1.xs('B', axis=0,level = 1).sum(axis = 0)
df1.xs('C', axis=0,level = 1).sum(axis = 0)

df1.sum(axis = 0, level = 1)

# -- 지점별 요일별 (축이 다르면 순차적으로 해야함)
df1.sum(axis = 0, level =1).sum(axis = 1, level =1)

# 3) 지점별 매출이 가장 높은 요일 출력
df1.sum(axis = 0, level =1).sum(axis = 1, level =1).idxmax(axis = 1)

# 4) 지역별 매출이 가장 높은 상위 3개의 월 확인
df2 = df1.sum(axis =0, level = 0).sum(axis = 1, level =0)
f1 = lambda x : Series(x.sort_values(ascending = False)[:3].index, index = ['1등','2등','3등'])
df2.apply(f1, axis = 0)


# professor.csv 파일을 읽고
pro = pd.read_csv('professor.csv', encoding = 'cp949')
# 1) position별로 최대 pay를 받는 교수 이름, position, pay 출력
p_max = pro.pivot_table(index = 'POSITION', values = 'PAY', aggfunc='max').reset_index()
pd.merge(pro, p_max)[['NAME','POSITION','PAY']]

# 2) position별로 평균 pay 보다 낮게 받는 교수 이름, position, pay 출력
p_mean = pro.pivot_table(index = 'POSITION', values = 'PAY', aggfunc='mean').reset_index()
p_total = pd.merge(pro, p_mean, on = 'POSITION')[['NAME','POSITION','PAY_x','PAY_y']]
p_mean.columns
p_total.loc[p_total['PAY_x'] < p_total['PAY_y'], ['NAME','POSITION','PAY_x','PAY_y']]



# groupby
# - 분리 - 적용(함수에 전달) - 결합
# - long data에서 수행 가능한 그룹 연산 (python에서는 wide data일때도 잘 작동)
# - 그룹핑 컬럼은 알아서 인덱스로 변경


emp = pd.read_csv('emp.csv')
emp.groupby(by,                 # 그룹핑 컬럼
            axis = 0,           # 그룹 연산 방향
            level,              # 멀티 인덱스일 경우 특정 레벨의 값을 그룹 컬럼으로 전달 할 수 있음 
            as_index = True,    # 그룹핑 컬럼의 인덱스 배치 여부(False를 쓰면 일반 컬럼으로 출력)
            group_keys,
            )

# 예제) emp에서 부서별 최대 연봉
emp.groupby('DEPTNO').max()           # DEPTNO 컬럼을 제외한 나머지 컬럼에 대해 모두 연산 수행
emp.groupby('DEPTNO')['SAL'].max()    # 특정 컬럼을 선택 시 groupby 객체 뒤에 나열

emp.groupby('DEPTNO', as_index = False).mean()          # 연산 가능한 컬럼만 나옴(숫자 컬럼만 나옴) 

emp.groupby('DEPTNO')[['SAL','COMM']].mean()  # 여러 컬럼 연산(선택) 시 리스트로 전달
emp.groupby(['DEPTNO','JOB'])['SAL'].mean()   # 그룹핑 컬럼 여러개 전달 가능(멀티 인덱스로 출력)


emp.groupby('DEPTNO')['SAL'].agg(['max','min'])                        # 여러 연산 함수를 전달 시 사용
emp.groupby('DEPTNO')[['SAL','COMM']].agg(['max','min'])               # SAL, COMM 컬럼에 대해 max, min 모두 연산
emp.groupby('DEPTNO')[['SAL','COMM']].agg({'SAL':'max','COMM':'min'})  # 각 컬럼별로 서로 다른 연산 함수 전달 시(NA무시)

df1['서울'].groupby(level = 0).sum()          # groupby 메서드에 level 전달 가능
df1['서울'].sum(axis = 0, level = 0)          # 위와 연산 결과 같음

# [ 참고 - in R ]
# ddply(emp, .(DEPTNO), summarise, v1=max(SAL), v2=min(SAL))
# ddply(emp, .(DEPTNO), summarise, v1=max(SAL), v2=min(COMM))

# [ 연습 문제 ]
# student.csv 파일과 exam_01.csv 파일을 읽고
std = pd.read_csv('student.csv', encoding = 'cp949')
ex1 = pd.read_csv('exam_01.csv', encoding = 'cp949')

# 1) 각 학년별 평균점수
std_total = pd.merge(std, ex1)
std_total.groupby('GRADE')['TOTAL'].mean()

std_total['TOTAL'].groupby(std_total['GRADE']).mean()   # 앞에 전체를 쓰지 않으면 groupby ()에 전체 객체를 또 전달해줘야함

# 2) 각 학년별 성별, 시험성적의 최대, 최소값
std_total['JUMIN'].astype('str').str[6].map({'1':'남자', '2':'여자'})      # 아래 행위와 같음
std_total['GENDER'] = std_total['JUMIN'].astype('str').str[6].replace({'1':'남자', '2':'여자'})

std_total.groupby(['GRADE','GENDER'])['TOTAL'].agg(['max','min'])
